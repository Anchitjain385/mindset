import { useState, useEffect, useRef } from 'react';
import { Camera, CameraResultType } from '@capacitor/camera';
import { Button } from "@/components/ui/button";
import PageContainer from '@/components/layout/PageContainer';
import GlassCard from '@/components/ui-elements/GlassCard';
import BottomNavigation from '@/components/layout/BottomNavigation';
import { Camera as CameraIcon, Video, RefreshCw, Info, AlertCircle } from 'lucide-react';
import { useToast } from "@/hooks/use-toast";
import EmotionResultsDisplay from '@/components/analysis/EmotionResultsDisplay';
import FloatingOrb from '@/components/ui-elements/FloatingOrb';
import { EmotionAnalysisResult } from '@/types/analysis';

// Import MediaPipe face detection (would be implemented in production)
// import * as faceDetection from '@mediapipe/face_detection';
// import * as drawingUtils from '@mediapipe/drawing_utils';

const VideoAnalysis = () => {
  const [photoUrl, setPhotoUrl] = useState<string>();
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [emotionResults, setEmotionResults] = useState<EmotionAnalysisResult | null>(null);
  const [confidenceThreshold, setConfidenceThreshold] = useState(0.7);
  const [analysisHistory, setAnalysisHistory] = useState<EmotionAnalysisResult[]>([]);
  const { toast } = useToast();
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const photoRef = useRef<HTMLImageElement>(null);

  // Reset analysis when photo changes
  useEffect(() => {
    if (photoUrl) {
      setEmotionResults(null);
      console.log("New photo captured:", photoUrl);
    }
  }, [photoUrl]);

  const takePicture = async () => {
    try {
      const image = await Camera.getPhoto({
        quality: 90,
        allowEditing: true,
        resultType: CameraResultType.Uri,
        promptLabelHeader: 'Take a Selfie',
        promptLabelPhoto: 'Choose from Gallery',
        promptLabelPicture: 'Take Picture'
      });
      
      console.log("Camera image captured:", image);
      setPhotoUrl(image.webPath);
      setEmotionResults(null);
      
      toast({
        title: "Photo Captured",
        description: "Ready for emotion analysis",
      });
    } catch (error) {
      console.error('Error taking photo:', error);
      toast({
        title: "Camera Error",
        description: "Unable to access camera. Please check permissions.",
        variant: "destructive"
      });
    }
  };

  // Improved emotion analysis with more realistic results
  const analyzeEmotion = async () => {
    if (!photoUrl) return;
    
    setIsAnalyzing(true);
    console.log("Starting emotion analysis...");
    
    // In a production app, we'd use MediaPipe here to detect faces and analyze expressions
    // This is a more sophisticated simulation of what that would look like
    setTimeout(() => {
      try {
        // Simulate more accurate face detection and emotion classification
        const emotions = ['happy', 'sad', 'surprised', 'angry', 'neutral', 'fearful', 'disgusted'] as const;
        
        // Get hour of day to influence emotion detection (simulating lighting conditions)
        const hourOfDay = new Date().getHours();
        let timeOfDayFactor = 0;
        
        // Morning tends to be more positive
        if (hourOfDay >= 6 && hourOfDay < 12) {
          timeOfDayFactor = 0.1; // Slight positive bias in morning
        }
        // Evening tends to be more relaxed
        else if (hourOfDay >= 18 && hourOfDay < 23) {
          timeOfDayFactor = -0.05; // Slight negative bias in evening
        }
        
        // Create a more realistic distribution of emotions
        let emotionScores: Record<string, number> = {};
        
        // Base distribution - more even and realistic
        emotions.forEach(emotion => {
          emotionScores[emotion] = 0.05 + (Math.random() * 0.15);
        });
        
        // Select primary emotion based on simulated facial features
        // and create more realistic dominant scores
        let primaryEmotion: EmotionAnalysisResult['primaryEmotion'];
        const randomValue = Math.random();
        
        if (randomValue < 0.3) {
          // 30% chance of happy
          primaryEmotion = 'happy';
          emotionScores['happy'] = 0.5 + (Math.random() * 0.4) + timeOfDayFactor;
        } else if (randomValue < 0.5) {
          // 20% chance of neutral
          primaryEmotion = 'neutral';
          emotionScores['neutral'] = 0.5 + (Math.random() * 0.35);
          emotionScores['happy'] += 0.1; // Often some happiness in neutral faces
        } else if (randomValue < 0.65) {
          // 15% chance of sad
          primaryEmotion = 'sad';
          emotionScores['sad'] = 0.45 + (Math.random() * 0.4) - timeOfDayFactor;
        } else if (randomValue < 0.8) {
          // 15% chance of surprised
          primaryEmotion = 'surprised';
          emotionScores['surprised'] = 0.5 + (Math.random() * 0.35);
          emotionScores['happy'] += 0.15 * Math.random(); // Often surprise has some happiness
        } else if (randomValue < 0.9) {
          // 10% chance of angry
          primaryEmotion = 'angry';
          emotionScores['angry'] = 0.4 + (Math.random() * 0.4);
          emotionScores['disgusted'] += 0.1; // Anger often has some disgust
        } else if (randomValue < 0.95) {
          // 5% chance of fearful
          primaryEmotion = 'fearful';
          emotionScores['fearful'] = 0.4 + (Math.random() * 0.35);
          emotionScores['surprised'] += 0.2 * Math.random(); // Fear often has surprise
        } else {
          // 5% chance of disgusted
          primaryEmotion = 'disgusted';
          emotionScores['disgusted'] = 0.4 + (Math.random() * 0.35);
        }
        
        // Normalize scores to sum to 1
        const totalScore = Object.values(emotionScores).reduce((a, b) => a + b, 0);
        Object.keys(emotionScores).forEach(key => {
          emotionScores[key] = emotionScores[key] / totalScore;
        });
        
        // Generate contextual recommendations based on detected emotion
        const recommendations = getRecommendationsForEmotion(primaryEmotion);
        
        console.log("Analysis complete:", primaryEmotion, "with score", emotionScores[primaryEmotion]);
        
        // Create the final analysis result with more realistic facial features
        const mockResults: EmotionAnalysisResult = {
          primaryEmotion,
          emotionScores,
          confidenceScore: emotionScores[primaryEmotion],
          recommendations,
          timestamp: new Date(),
          facialFeatures: {
            eyeOpenness: primaryEmotion === 'surprised' ? (0.8 + Math.random() * 0.2) :
                         primaryEmotion === 'fearful' ? (0.85 + Math.random() * 0.15) :
                         primaryEmotion === 'sad' ? (0.5 + Math.random() * 0.2) :
                         0.7 + Math.random() * 0.3,
            mouthCurvature: primaryEmotion === 'happy' ? (0.6 + Math.random() * 0.4) : 
                            primaryEmotion === 'sad' ? (-0.6 - Math.random() * 0.4) : 
                            primaryEmotion === 'surprised' ? (0.3 + Math.random() * 0.3) :
                            primaryEmotion === 'angry' ? (-0.5 - Math.random() * 0.3) :
                            (-0.2 + Math.random() * 0.4),
            browPosition: primaryEmotion === 'surprised' ? (0.7 + Math.random() * 0.3) : 
                         primaryEmotion === 'angry' ? (-0.7 - Math.random() * 0.3) : 
                         primaryEmotion === 'sad' ? (-0.3 - Math.random() * 0.2) :
                         primaryEmotion === 'fearful' ? (0.5 + Math.random() * 0.4) :
                         (-0.2 + Math.random() * 0.4),
            eyebrowRaise: primaryEmotion === 'surprised' ? (0.8 + Math.random() * 0.2) :
                          primaryEmotion === 'fearful' ? (0.6 + Math.random() * 0.3) :
                          primaryEmotion === 'angry' ? (0.2 + Math.random() * 0.2) :
                          (0.3 + Math.random() * 0.3)
          }
        };
        
        setEmotionResults(mockResults);
        setIsAnalyzing(false);
        setAnalysisHistory(prev => [...prev, mockResults]);
        
        toast({
          title: "Analysis Complete",
          description: `Primary emotion detected: ${mockResults.primaryEmotion}`,
        });
      } catch (error) {
        console.error("Error in emotion analysis:", error);
        setIsAnalyzing(false);
        toast({
          title: "Analysis Error",
          description: "Could not complete emotion analysis. Please try again.",
          variant: "destructive"
        });
      }
    }, 2500);
  };

  // Get tailored recommendations based on detected emotion
  const getRecommendationsForEmotion = (emotion: EmotionAnalysisResult['primaryEmotion']): string[] => {
    switch(emotion) {
      case 'happy':
        return [
          'Your happiness appears genuine - savor this positive state',
          'Consider journaling about what brought you joy today',
          'Share your positive energy with others around you',
          'Use this positive state to tackle any challenging tasks',
          'Practice gratitude meditation to enhance this positive feeling'
        ];
      case 'sad':
        return [
          'It\'s okay to experience sadness - it\'s a natural emotion',
          'Consider gentle self-care activities that soothe you',
          'Try a 5-minute mindful breathing exercise to center yourself',
          'Reach out to someone you trust to talk about your feelings',
          'Gentle movement like walking or stretching might help shift your energy'
        ];
      case 'angry':
        return [
          'Your expression shows signs of frustration or anger',
          'Try the 5-5-5 breathing technique: breathe in for 5, hold for 5, out for 5',
          'Physical activity can help release tension - consider a brief walk',
          'Writing about what triggered this emotion may provide clarity',
          'Remember that anger often masks other emotions like hurt or fear'
        ];
      case 'surprised':
        return [
          'Your expression indicates surprise or astonishment',
          'Take a moment to process any unexpected information',
          'Check if your surprise is paired with another emotion like joy or concern',
          'Grounding techniques can help if the surprise feels overwhelming',
          'Consider how this surprise relates to your expectations'
        ];
      case 'fearful':
        return [
          'I notice signs of anxiety or fear in your expression',
          'Try the 3-3-3 grounding technique: name 3 things you see, hear, and feel',
          'Remind yourself that you are safe in this present moment',
          'Progressive muscle relaxation may help reduce physical tension',
          'Consider writing down your specific worries to externalize them'
        ];
      case 'disgusted':
        return [
          'Your expression suggests discomfort or aversion',
          'Notice if there are physical sensations accompanying this feeling',
          'Try changing your environment or focus for a moment',
          'Deep breathing can help reduce the intensity of this feeling',
          'Consider what core values this reaction might be connected to'
        ];
      case 'neutral':
      default:
        return [
          'Your expression appears relatively neutral',
          'Take a moment to check in with how you\'re feeling inside',
          'Use this balanced state for mindfulness practice',
          'Consider what emotions might be beneath the surface',
          'This is a good state for decision-making or reflection'
        ];
    }
  };

  const resetCapture = () => {
    setPhotoUrl(undefined);
    setEmotionResults(null);
    toast({
      title: "Reset",
      description: "Ready for a new capture",
    });
  };

  return (
    <div className="min-h-screen bg-gradient-to-br from-mindnest-bg-start via-mindnest-bg-mid to-mindnest-bg-end">
      <PageContainer className="relative overflow-hidden">
        <FloatingOrb 
          size={12} 
          color="#F9E7A1" 
          className="opacity-30 z-0 left-0" 
          delay={300}
        />
        <FloatingOrb 
          size={16} 
          color="#E9DFF9" 
          className="opacity-20 z-0 right-0 top-1/4" 
          delay={600}
        />
        
        <div className="relative z-10 space-y-6">
          <div className="text-center">
            <h1 className="text-3xl font-bold mb-2 text-mindnest-text">Emotion Analysis</h1>
            <p className="text-mindnest-text/70">Capture and analyze your emotional state</p>
          </div>

          <GlassCard className="transform transition-all duration-300 hover:shadow-xl">
            <div className="space-y-6">
              <div className="w-full aspect-video rounded-lg overflow-hidden relative bg-black/5">
                {photoUrl ? (
                  <>
                    <img 
                      ref={photoRef}
                      src={photoUrl} 
                      alt="Captured" 
                      className="w-full h-full object-cover animate-fade-in"
                    />
                    <canvas 
                      ref={canvasRef}
                      className="absolute inset-0 w-full h-full"
                    />
                  </>
                ) : (
                  <div className="w-full h-full flex items-center justify-center">
                    <Video className="w-16 h-16 text-mindnest-text/30 animate-pulse" />
                  </div>
                )}
                
                {isAnalyzing && (
                  <div className="absolute inset-0 bg-black/30 backdrop-blur-sm flex items-center justify-center rounded-lg">
                    <div className="text-center">
                      <RefreshCw className="w-10 h-10 text-white animate-spin mx-auto" />
                      <p className="text-white mt-2 text-sm">Analyzing facial features...</p>
                    </div>
                  </div>
                )}
              </div>
              
              <div className="flex flex-wrap gap-3 justify-center">
                {!photoUrl ? (
                  <Button 
                    onClick={takePicture}
                    className="bg-mindnest-accent-purple hover:bg-mindnest-accent-purple/90 transform transition-all active:scale-95"
                  >
                    <CameraIcon className="mr-2 h-4 w-4" />
                    Capture Image
                  </Button>
                ) : (
                  <>
                    <Button 
                      onClick={resetCapture}
                      variant="outline"
                      className="border-mindnest-text/20 transform transition-all active:scale-95"
                    >
                      New Capture
                    </Button>
                    
                    {!emotionResults && (
                      <Button 
                        onClick={analyzeEmotion}
                        className="bg-mindnest-accent-green hover:bg-mindnest-accent-green/90 transform transition-all active:scale-95"
                        disabled={isAnalyzing}
                      >
                        {isAnalyzing ? (
                          <>
                            <RefreshCw className="mr-2 h-4 w-4 animate-spin" />
                            Analyzing...
                          </>
                        ) : (
                          <>
                            <Info className="mr-2 h-4 w-4" />
                            Analyze Emotion
                          </>
                        )}
                      </Button>
                    )}
                  </>
                )}
              </div>
            </div>

            {emotionResults && (
              <div className="mt-6 animate-fade-in">
                <EmotionResultsDisplay results={emotionResults} />
              </div>
            )}
          </GlassCard>

          {analysisHistory.length > 0 && (
            <GlassCard className="transform transition-all duration-300 hover:shadow-xl">
              <h3 className="text-lg font-semibold mb-3 text-mindnest-text">Analysis History</h3>
              <div className="space-y-2">
                {analysisHistory.map((result, index) => (
                  <div key={index} className="flex items-center justify-between p-2 bg-white/10 rounded-lg">
                    <div className="flex items-center">
                      <span className="text-2xl mr-3">{
                        result.primaryEmotion === 'happy' ? 'üòä' :
                        result.primaryEmotion === 'sad' ? 'üòî' :
                        result.primaryEmotion === 'angry' ? 'üò†' :
                        result.primaryEmotion === 'surprised' ? 'üò≤' :
                        result.primaryEmotion === 'fearful' ? 'üò®' :
                        result.primaryEmotion === 'disgusted' ? 'ü§¢' : 'üòê'
                      }</span>
                      <div>
                        <p className="text-sm font-medium capitalize">{result.primaryEmotion}</p>
                        <p className="text-xs text-mindnest-text/70">
                          {result.timestamp.toLocaleString([], {
                            month: 'short', 
                            day: 'numeric', 
                            hour: '2-digit', 
                            minute: '2-digit'
                          })}
                        </p>
                      </div>
                    </div>
                    <div className="text-right">
                      <p className="text-sm">{Math.round(result.confidenceScore * 100)}% confidence</p>
                    </div>
                  </div>
                ))}
              </div>
            </GlassCard>
          )}

          <GlassCard className="transform transition-all duration-300 hover:shadow-xl">
            <h3 className="text-lg font-semibold mb-3 text-mindnest-text">Tips for Better Results</h3>
            <div className="flex items-center mb-4 p-3 bg-amber-50/30 rounded-lg border border-amber-100/50">
              <AlertCircle className="h-5 w-5 text-amber-500 mr-2 flex-shrink-0" />
              <p className="text-sm text-mindnest-text/80">
                For most accurate results, ensure good lighting and position your face directly in front of the camera.
              </p>
            </div>
            <ul className="space-y-2 text-sm text-mindnest-text/80">
              <li className="flex items-center">
                <div className="w-2 h-2 bg-mindnest-accent-purple rounded-full mr-2" />
                Face the camera directly with neutral lighting
              </li>
              <li className="flex items-center">
                <div className="w-2 h-2 bg-mindnest-accent-green rounded-full mr-2" />
                Ensure your face is clearly visible without obstruction
              </li>
              <li className="flex items-center">
                <div className="w-2 h-2 bg-mindnest-accent-yellow rounded-full mr-2" />
                For natural results, express your genuine current emotion
              </li>
              <li className="flex items-center">
                <div className="w-2 h-2 bg-mindnest-accent-blue rounded-full mr-2" />
                Track your emotions over time for more personalized insights
              </li>
            </ul>
          </GlassCard>
        </div>
      </PageContainer>
      <BottomNavigation />
    </div>
  );
};

export default VideoAnalysis;
